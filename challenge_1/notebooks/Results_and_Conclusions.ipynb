{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80% of time was spent data wrangling - mostly in pandas with some postgreSQL and Dask\n",
    "\n",
    "10% of time was spent on data analysis\n",
    "\n",
    "10% of time was split between forecasting using linear machine learning, gradient boosting and CNN, LSTM / regular Neural Networks\n",
    "\n",
    "LightGBM is a very fast and straightforward to use package - building models takes a fraction of the time it took to build other forcasting models. If I had more time I would work on incorporating other boosted trees algorithms, fine tune and ensemble.\n",
    "\n",
    "Cluster using a non orthodox approach of using images of energy use over time then using image based clustering seemed to have worked suprisingly well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 day forecast results\n",
    "\n",
    "A far wider run of households would have been preferable (eg 100)\n",
    "\n",
    "All forecasts below (unless otherwise indicated) used half hourly timestep data.\n",
    "\n",
    "In models below the figure in brackets [x] represents the overall RMSE score for the forecast\n",
    "\n",
    "The numbers trailing the [x] figure represent RMSE for each time step averged over the entire day\n",
    "\n",
    "All models below (unless otherwise indicated) forecast 7 days ahead for these households: ['mac000230', 'mac000100']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple baseline historical forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 4_0_forecast_daily_baseline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train: 32592, split weeks: 97.0\n",
    "test: 32592, split weeks: 97.0\n",
    "\n",
    "week-one_year_ago: [0.310] 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3\n",
    "weekly: [0.301] 0.2, 0.3, 0.3, 0.2, 0.3, 0.3, 0.3\n",
    "daily: [0.296] 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3\n",
    "\n",
    "train: 32592, split weeks: 97.0\n",
    "test: 32592, split weeks: 97.0\n",
    "\n",
    "week-one_year_ago: [0.301] 0.3, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3\n",
    "weekly: [0.301] 0.3, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3\n",
    "daily: [0.291] 0.3, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKlearn ML models:\n",
    "\n",
    "    7 day Multivariate but with only two variates as below\n",
    "    \n",
    "    data_col = ['energy(kWh/hh)'], train_cols=['temperature', 'humidity']\n",
    "    \n",
    "    all forecast for 'mac00230' and 'mac00100'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 4_2_a_forecast_ML_direct_day.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso: rmse=[0.287] 0.1, 0.1, 0.1, 0.1, 0.2, 0.1, 0.3\n",
    "elastic net: rmse=[0.287] 0.1, 0.1, 0.1, 0.1, 0.2, 0.1, 0.3\n",
    "ridge: rmse=[0.328] 0.1, 0.2, 0.2, 0.1, 0.2, 0.1, 0.3\n",
    "ranscac regressor: rmse=[0.358] 0.2, 0.2, 0.2, 0.1, 0.2, 0.1, 0.3\n",
    "passive aggressive regressor: rmse=[0.331] 0.2, 0.2, 0.2, 0.1, 0.2, 0.1, 0.3\n",
    "sgd regressor: rmse=[0.286] 0.1, 0.1, 0.1, 0.1, 0.2, 0.1, 0.3\n",
    "linear regression: rmse=[0.338] 0.1, 0.2, 0.2, 0.1, 0.2, 0.1, 0.3\n",
    "lasso lars: rmse=[0.287] 0.1, 0.1, 0.1, 0.1, 0.2, 0.1, 0.3\n",
    "huber regressor: rmse=[0.321] 0.1, 0.2, 0.2, 0.1, 0.2, 0.1, 0.3\n",
    "Best overall algorithm: sgd regressor\n",
    "\n",
    "lasso: rmse=[0.263] 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2\n",
    "elastic net: rmse=[0.263] 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2\n",
    "ridge: rmse=[0.314] 0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2\n",
    "ranscac regressor: rmse=[0.310] 0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2\n",
    "passive aggressive regressor: rmse=[0.317] 0.2, 0.2, 0.1, 0.1, 0.1, 0.1, 0.3\n",
    "sgd regressor: rmse=[0.270] 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2\n",
    "linear regression: rmse=[0.327] 0.2, 0.2, 0.1, 0.1, 0.1, 0.1, 0.2\n",
    "lasso lars: rmse=[0.263] 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2\n",
    "huber regressor: rmse=[0.327] 0.2, 0.2, 0.1, 0.1, 0.1, 0.1, 0.2\n",
    "Best overall algorithm: lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 4_2_b_forecast_ML_recursive.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranscac regressor: [0.302] 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.1\n",
    "linear regression: [0.248] 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2\n",
    "huber regressor: [0.273] 0.1, 0.1, 0.2, 0.1, 0.2, 0.1, 0.1\n",
    "lasso: [0.268] 0.2, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2\n",
    "sgd regressor: [0.246] 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2\n",
    "passive aggressive regressor: [0.701] 0.3, 0.3, 0.4, 0.6, 0.5, 0.6, 1.0\n",
    "ridge: [0.248] 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2\n",
    "lasso lars: [0.268] 0.2, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2\n",
    "elastic net: [0.268] 0.2, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2\n",
    "Best overall algorithm: huber regressor\n",
    "\n",
    "ranscac regressor: [0.334] 0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.3\n",
    "linear regression: [0.272] 0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2\n",
    "huber regressor: [0.313] 0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2\n",
    "lasso: [0.313] 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.2\n",
    "sgd regressor: [0.273] 0.2, 0.2, 0.1, 0.1, 0.1, 0.1, 0.2\n",
    "passive aggressive regressor: [0.419] 0.3, 0.3, 0.3, 0.2, 0.4, 0.4, 0.4\n",
    "ridge: [0.272] 0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2\n",
    "lasso lars: [0.313] 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.2\n",
    "elastic net: [0.313] 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.2\n",
    "Best overall algorithm: sgd regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Models\n",
    "\n",
    "Implemented in Keras and Tensorflow\n",
    "\n",
    "* 4_5_a_forecast_multichannel_cnn.py \n",
    "\n",
    "multichannel multi-step cnn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn: [0.242] 0.1, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2\n",
    "    \n",
    "cnn: [0.302] 0.3, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 4_5_b_forecast_multiheaded_cnn.py \n",
    "\n",
    "multi headed multi-step cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn: [0.250] 0.2, 0.2, 0.2, 0.1, 0.2, 0.1, 0.2\n",
    "\n",
    "cnn: [0.287] 0.2, 0.2, 0.2, 0.2, 0.1, 0.1, 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model\n",
    "\n",
    "Very slow compared to CNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 4_7_forecast_multivariate_encoder_decoder_lstm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'Rich'models\n",
    "\n",
    "Both the LightGBM and Pytorch embedded categrical models below  in the approach from the models above.\n",
    "\n",
    "While more multivariate inputs could have been used in the models above, the LightGBM and Pytorch models incorporate a broad range of \n",
    "numerical and categorical types that would be difficult/complex to implement in the models above.\n",
    "\n",
    "RMSE results cannot be directly compared with models 4_0 through 4_5 as those models were only forecasting two household datasets.\n",
    "\n",
    "Here we forecast accross 544 households. However the two 'rich models' can be directly compared for performance.\n",
    "\n",
    "As far as complexity in model building the Pytoch model was by far more time consuming to build, and took significantly more time to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Model\n",
    "\n",
    "Implented in LightGBM\n",
    "\n",
    "(Note 4_4_a_forecast_GB_daily_ds.ipynb uses the daily dataset for forecasting - but this is fundamentally problematic as energy use dependent variables (eg energy_mean) were used directly to predict energy_sum - not relistic).\n",
    "\n",
    "Interestingly the generated feature 'time from sunrise' is the second most important feture for the predictive model.\n",
    "\n",
    "* 4_4_b_forecast_GB_hh_ds.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The rmse of prediction is: 0.37470788223913915"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Embedded Categorical Model\n",
    "\n",
    "Modeled on Fastai Rossman notebook with background here:\n",
    "    \n",
    "https://arxiv.org/abs/1604.06737\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#key code\n",
    "https://github.com/fastai/fastai/blob/master/old/fastai/column_data.py\n",
    "\n",
    "class ColumnarDataset(Dataset):\n",
    "    \n",
    "class MixedInputModel(nn.Module):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch\n",
    "0 RMSE 0.378365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes: ARIMA \n",
    "\n",
    "a quick first pass at an ARIMA model can be found in 4_1_forecast_ARIMA but I did not have enough time to re-visit to incorporate in this results dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
