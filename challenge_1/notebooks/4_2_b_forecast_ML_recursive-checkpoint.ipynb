{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive multi-step forecast with linear algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'forecast_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0d955a934113>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../scripts/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mforecast_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mav_scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'forecast_utils'"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"../scripts/\")\n",
    "from forecast_utils import av_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-3-3e05e254bd9f>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-3e05e254bd9f>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    MAC_NAME='mac000230\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "PATH='../input/merged_data/'\n",
    "MAC_NAME='mac000230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAILY_SAMPLE_RATE=48\n",
    "#one week ahead\n",
    "FORECAST_DAYS=7\n",
    "TEST_WEEKS = 1\n",
    "TEST_SAMPLES=TEST_WEEKS*FORECAST_DAYS*DAILY_SAMPLE_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate dataset into train/test sets\n",
    "def split_dataset(data):\n",
    "    #use last n weeks for test (enough for validation and test)\n",
    "    week_hh = FORECAST_DAYS*DAILY_SAMPLE_RATE\n",
    "    train=data[:-TEST_SAMPLES]\n",
    "    test = data[-TEST_SAMPLES:]\n",
    "    # restructure into windows of weekly data\n",
    "    train = np.array(np.split(train, len(train)/week_hh))\n",
    "    test = np.array(np.split(test, len(test)/week_hh))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "    scores = list()\n",
    "    # calculate an RMSE score for each day\n",
    "    for i in range(actual.shape[1]):\n",
    "        # calculate mse\n",
    "        mse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "        # calculate rmse\n",
    "        rmse = sqrt(mse)\n",
    "        # store\n",
    "        scores.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate overall RMSE\n",
    "    s = 0\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            s += (actual[row, col] - predicted[row, col]) ** 2\n",
    "    score = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "    return score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def print_scores(name, score, scores):\n",
    "    #s_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "    #print('%s: [%.3f] %s' % ('Half hourly', score, s_scores))\n",
    "    n_chunks = len(scores)/DAILY_SAMPLE_RATE\n",
    "    print(type(scores))\n",
    "    scores_chunked = np.array_split(scores, n_chunks)\n",
    "    av_scores = []\n",
    "    for chunk in scores_chunked:\n",
    "        av_scores.append(np.average(chunk))\n",
    "    w_scores = ', '.join(['%.1f' % s for s in av_scores])\n",
    "    print('%s: [%.3f] %s' % (name, score, w_scores))\n",
    "\n",
    "def print_best_algo(name_score):\n",
    "    best_alg = ''\n",
    "    best_score = 0\n",
    "    for i, n_s in enumerate(name_score):\n",
    "        if i == 0:\n",
    "            best_alg=n_s[0]\n",
    "            best_score=n_s[1]\n",
    "        else:\n",
    "            if n_s[1]<best_score:\n",
    "                best_alg=n_s[0]\n",
    "                best_score=n_s[1]\n",
    "    print('Best overall algorithm: {0}'.format(best_alg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a list of ml models\n",
    "def get_models(models=dict()):\n",
    "    # linear models\n",
    "    models['linear regression'] = LinearRegression()\n",
    "    models['lasso'] = Lasso()\n",
    "    models['ridge'] = Ridge()\n",
    "    models['elastic net'] = ElasticNet()\n",
    "    models['huber regressor'] = HuberRegressor()\n",
    "    #models['lars'] = Lars()\n",
    "    models['lasso lars'] = LassoLars()\n",
    "    models['passive aggressive regressor'] = PassiveAggressiveRegressor(max_iter=1000, tol=1e-3)\n",
    "    models['ranscac regressor'] = RANSACRegressor(min_samples=7)\n",
    "    models['sgd regressor'] = SGDRegressor(max_iter=5000, tol=1e-3)\n",
    "    print('Defined %d models' % len(models))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a feature preparation pipeline for a model\n",
    "def make_pipeline(model):\n",
    "    steps = list()\n",
    "    # standardization\n",
    "    steps.append(('standardize', StandardScaler()))\n",
    "    # normalization\n",
    "    steps.append(('normalize', MinMaxScaler()))\n",
    "    # the model\n",
    "    steps.append(('model', model))\n",
    "    # create pipeline\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a recursive multi-step forecast\n",
    "# make a prediction for one time step, taking the prediction, feed it into the model as an input in order to predict the subsequent time step. Repeat until the desired number of steps have been forecast.\n",
    "def forecast(model, input_x, n_input):\n",
    "    yhat_sequence = list()\n",
    "    input_data = [x for x in input_x]\n",
    "    for j in range(FORECAST_DAYS*DAILY_SAMPLE_RATE):\n",
    "        # prepare the input data\n",
    "        X = np.array(input_data[-n_input:]).reshape(1, n_input)\n",
    "        # make a one-step forecast\n",
    "        yhat = model.predict(X)[0]\n",
    "        # add to the result\n",
    "        yhat_sequence.append(yhat)\n",
    "        # add the prediction to the input\n",
    "        input_data.append(yhat)\n",
    "    return yhat_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert windows of weekly multivariate data into a series of total power\n",
    "def to_series(data):\n",
    "    # extract just the total power from each week\n",
    "    series = [week[:, 0] for week in data]\n",
    "    # flatten into a single series\n",
    "    series = np.array(series).flatten()\n",
    "    return series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert history into inputs and outputs\n",
    "def to_supervised(history, n_input):\n",
    "    # convert history to a univariate series\n",
    "    data = to_series(history)\n",
    "    X, y = list(), list()\n",
    "    ix_start = 0\n",
    "    # step over the entire history one time step at a time\n",
    "    for i in range(len(data)):\n",
    "        # define the end of the input sequence\n",
    "        ix_end = ix_start + n_input\n",
    "        # ensure we have enough data for this instance\n",
    "        if ix_end < len(data):\n",
    "            X.append(data[ix_start:ix_end])\n",
    "            y.append(data[ix_end])\n",
    "        # move along one time step\n",
    "        ix_start += 1\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model and make a forecast\n",
    "def sklearn_predict(model, history, n_input):\n",
    "    # prepare data\n",
    "    train_x, train_y = to_supervised(history, n_input)\n",
    "    # make pipeline\n",
    "    pipeline = make_pipeline(model)\n",
    "    # fit the model\n",
    "    pipeline.fit(train_x, train_y)\n",
    "    # predict the week, recursively\n",
    "    yhat_sequence = forecast(pipeline, train_x[-1, :], n_input)\n",
    "    return yhat_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a single model\n",
    "def evaluate_model(model, train, test, n_input, data_column=0):\n",
    "    # history is a list of weekly data\n",
    "    history = [x for x in train]\n",
    "    # walk-forward validation over each week\n",
    "    predictions = list()\n",
    "    print('len(test): {0}'.format(len(test)))\n",
    "    for i in range(len(test)):\n",
    "        # predict the week\n",
    "        yhat_sequence = sklearn_predict(model, history, n_input)\n",
    "        # store the predictions\n",
    "        predictions.append(yhat_sequence)\n",
    "        # get real observation and add to history for predicting the next week\n",
    "        history.append(test[i, :])\n",
    "    predictions = np.array(predictions)\n",
    "    # evaluate predictions days for each week\n",
    "    actuals = test[:, :, data_column]\n",
    "    score, scores = evaluate_forecasts(actuals, predictions)\n",
    "    return score, scores, actuals, predictions\n",
    "\n",
    "def eval_model(name, model, train, test, n_input, data_column=0):\n",
    "    print('>eval_model() {0}'.format(name))\n",
    "    # evaluate and get scores, energy(kWh/hh) is the first column in our dataset\n",
    "    score, scores, actuals, predictions = evaluate_model(model, train, test, n_input, data_column)\n",
    "    # summarize scores\n",
    "    print_scores(name, score, scores)\n",
    "    av = av_scores(scores, DAILY_SAMPLE_RATE)\n",
    "    # plot scores\n",
    "    return av, actuals, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Read in data\n",
    "dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "dataset = pd.read_csv('{0}LCLid/clean_{1}.csv'.format(PATH, MAC_NAME), parse_dates=['day_time'], date_parser=dateparse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsample for testing\n",
    "dataset = dataset[-1*(4*DAILY_SAMPLE_RATE*FORECAST_DAYS):]\n",
    "\n",
    "dataset.set_index(['day_time'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original data is to 3 decimal places\n",
    "dataset['energy(kWh/hh)'] = dataset['energy(kWh/hh)'].round(3)\n",
    "dataset['energy(Wh/hh)'] = dataset['energy(kWh/hh)'].multiply(1000)\n",
    "\n",
    "dataset =  dataset[['energy(Wh/hh)', 'temperature', 'humidity']]\n",
    "dataset=dataset.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plot the dataset\n",
    "ts = dataset['energy(Wh/hh)'].values\n",
    "ds = dataset.index.values\n",
    "\n",
    "#plt.plot(ds, ts)\n",
    "#plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "train, test = split_dataset(dataset.values)\n",
    "# prepare the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "n_input = FORECAST_DAYS*DAILY_SAMPLE_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate each model\n",
    "days = ['sun', 'mon', 'tue', 'wed', 'thr', 'fri', 'sat']\n",
    "avs=[]\n",
    "actuals=[]\n",
    "predictions=[]\n",
    "names=[]\n",
    "score_list = []\n",
    "for name, model in models.items():\n",
    "    # evaluate and get scores\n",
    "    av, actual, prediction = eval_model(name, model, train, test, n_input, data_column=0)\n",
    "    names.append(name)\n",
    "    avs.append(av)\n",
    "    score_list.append((name, av))\n",
    "    predictions.append(prediction)\n",
    "    actuals.append(actual)\n",
    "\n",
    "for name, av in zip(names, avs):\n",
    "    plt.plot(days, av, marker='o', label=name)\n",
    "    plt.ylabel('RSWE Wh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show plot\n",
    "plt.legend()\n",
    "plt.savefig('plots/4_2_b_{0}_{1}_day_forecast_rmse.png'.format(MAC_NAME, FORECAST_DAYS))\n",
    "plt.show()\n",
    "\n",
    "plt.show(block=False)\n",
    "plt.close()\n",
    "\n",
    "i=0\n",
    "hh=range(FORECAST_DAYS*DAILY_SAMPLE_RATE)\n",
    "for name, actual, pred in zip(names, actuals, predictions):\n",
    "    plt.subplot(len(models.items()), 1, i+1)\n",
    "    actual=actual.flatten()\n",
    "    plt.plot(hh, actual, label='actual', color='k')\n",
    "    prediction = pred.flatten()\n",
    "    plt.plot(hh, prediction,  label='predicted', color='r')\n",
    "    plt.title(name, fontsize=10)\n",
    "    plt.ylabel('Wh/hh')\n",
    "    i+=1\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('plots/4_2_b_{0}_{1}_day_forecast_actuals.png'.format(MAC_NAME, FORECAST_DAYS))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "best_alg = print_best_algo(score_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
